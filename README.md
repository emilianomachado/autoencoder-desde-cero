# Autoencoder desde Cero

ImplementaciÃ³n de un **Autoencoder** utilizando Python en Google Colab.  
Este proyecto muestra cÃ³mo construir, entrenar y analizar un autoencoder bÃ¡sico sin utilizar frameworks de redes neuronales avanzados, con el objetivo de comprender profundamente su funcionamiento interno.

---

## ğŸ§  Â¿QuÃ© es un Autoencoder?

Un **Autoencoder** es una red neuronal que aprende a **comprimir (codificar)** los datos a un espacio de menor dimensiÃ³n y luego **reconstruirlos (decodificar)**.  

Su objetivo principal es aprender representaciones internas Ãºtiles de los datos, por ejemplo:

- ReducciÃ³n de dimensionalidad  
- EliminaciÃ³n de ruido (Denoising Autoencoders)  
- CompresiÃ³n  
- ExtracciÃ³n de caracterÃ­sticas  
- Representaciones latentes

Un Autoencoder consta de:

- **Encoder** â†’ reduce la dimensionalidad  
- **Latent space** â†’ representaciÃ³n comprimida  
- **Decoder** â†’ intenta reconstruir la entrada original  

El entrenamiento se basa en minimizar el error entre la entrada y la salida reconstruida.

---

## ğŸ“‚ Contenido del proyecto

Este repositorio incluye:

- `Autoencoders.ipynb`  
  Notebook con:
  - ImplementaciÃ³n del autoencoder
  - DefiniciÃ³n del encoder y decoder
  - FunciÃ³n de costo y optimizaciÃ³n
  - Entrenamiento paso a paso
  - GrÃ¡ficos y visualizaciÃ³n de resultados
  - Ejemplos de compresiÃ³n y reconstrucciÃ³n

---

## ğŸš€ Â¿CÃ³mo ejecutar el proyecto?

1. AbrÃ­ el notebook en Google Colab.  
2. EjecutÃ¡ todas las celdas en orden.  
3. PodÃ©s modificar parÃ¡metros como:
   - DimensiÃ³n de la capa latente
   - Funciones de activaciÃ³n
   - Ã‰pocas de entrenamiento
   - Dataset utilizado
   - Tasa de aprendizaje

Esto te permite experimentar con distintas arquitecturas y niveles de compresiÃ³n.

---

## ğŸ›  Requisitos

Este notebook puede ejecutarse directamente en Google Colab, sin instalaciones adicionales.

LibrerÃ­as utilizadas:

- NumPy  
- Matplotlib  
- (Opcional) Otros mÃ³dulos estÃ¡ndar de Python para graficar o manipular datos.

---

## ğŸ“ˆ Resultados

El notebook permite visualizar:

- Diferencia entre entrada y salida reconstruida  
- EvoluciÃ³n de la funciÃ³n de costo  
- RepresentaciÃ³n latente comprimida  
- Efecto de diferentes arquitecturas en la calidad de reconstrucciÃ³n  

---

## ğŸ§ª Conceptos clave implementados

- CodificaciÃ³n y decodificaciÃ³n  
- RepresentaciÃ³n latente  
- Redes neuronales simÃ©tricas  
- FunciÃ³n de reconstrucciÃ³n  
- Entrenamiento no supervisado  
- CompresiÃ³n mediante aprendizaje automÃ¡tico  

---

## ğŸ“„ Licencia

Este proyecto es de uso libre para estudio y experimentaciÃ³n.

---

## âœ¨ Autor

Proyecto realizado por **Emiliano Machado** como parte del estudio de redes neuronales y modelos de representaciÃ³n.
